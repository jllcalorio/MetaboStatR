% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performPreprocessingPeakData.R
\name{performPreprocessingPeakData}
\alias{performPreprocessingPeakData}
\title{Perform Data Preprocessing on a Raw Data (csv)}
\usage{
performPreprocessingPeakData(
  raw_data,
  filterMissing = 20,
  denMissing = 5,
  driftBatchCorrection = TRUE,
  filterMaxRSD = 30,
  filterMaxRSD_by = c("SQC", "EQC", "both")[2],
  filterMaxVarSD = 10,
  dataNormalize = c("none", "SpecificGravity", "sum", "median", "PQN1", "PQN2",
    "groupPQN", "quantile")[2],
  refSample = NULL,
  groupSample = NULL,
  dataTransform = c("none", "log10", "sqrt", "cbrt")[2],
  dataScalePCA = c("none", "mean", "meanSD", "meanSD2")[3],
  dataScaleOPLSDA = c("none", "mean", "meanSD", "meanSD2")[4],
  outliers = NULL
)
}
\arguments{
\item{raw_data}{A csv file having the following characteristics:
\itemize{
\item 1st row: Contains QC and the groups (with/out spaces).
\item 2nd row: Contains SQC, EQC, and the same groups as in the 1st row.
\item 3rd row: The sample names, ideally shortened versions to make it easier to view in visualizations, without spaces.
\item 4th row: The batch numbers.
\item 5th row: The injection sequence.
\item 6th row: The osmolality values or specific gravity.
\item Others below:
\item Missing values are best to be left or encoded as 0s.
}}

\item{filterMissing}{Numeric. Minimum \%missing in all sample groups required to remove feature}

\item{denMissing}{Numeric. A value to be used in missing value imputation. A denominator in 1/denMissing.}

\item{driftBatchCorrection}{Boolean. If \code{TRUE} (default), perform multi-batch alignment to merge features artificially split between batches.}

\item{filterMaxRSD}{Numeric. The threshold for the Relative Standard Deviation (RSD). Suggestions below. RSD is used to assess and filter out unreliable metabolites, ensuring that only high-quality, reproducible data are used for statistical and biological interpretation. In metabolomics, RSD is commonly calculated for each metabolite across Quality Control (QC) samples. QC samples are repeated pooled samples meant to assess the analytical precision and reproducibility of the instrument and the experimental setup.
\itemize{
\item 20: for LC-MS analyzed data
\item 30: for GC-MS analyzed data
}}

\item{filterMaxRSD_by}{String. Choose below where to apply the RSD filtering in \code{filterMaxRSD}.
\itemize{
\item "SQC": Apply on Sample QCs only.
\item "EQC: Apply on Extract QCs only.
\item "both": Apply on both.
}
Defaults to "EQC".}

\item{filterMaxVarSD}{Numeric. Remove nth percentile of features with the lowest variability (e.g., 10 for 10\%). Set to \code{NULL} to skip this filtering.}

\item{dataNormalize}{String. Perform data normalization. Options are:
\itemize{
\item "none": No normalization.
\item "SpecificGravity: Normalization using specific gravity, if provided. Otherwise, normalized by 'sum'.
\item "sum": Normalization by sum.
\item "median": Normalization by median.
\item "PQN1": Probabilistic Quotient Normalization (PQN) according to global median approach."
\item "PQN2": Probabilistic Quotient Normalization (PQN) using a reference sample indicated in \code{refSample} as the reference sample in the normalization."
\item "groupPQN": Group Probabilistic Quotient Normalization using pooled group indicated in \code{groupSample}.
\item "quantile": Normalization by quantile,
}
Defaults to 'SpecificGravity' is present, otherwise, normalization by 'sum' will be performed.}

\item{refSample}{String. The reference sample in the case of normalization method "PQN2". Must be in the samples, and is not part of "outliers" vector c("SQC", "EQC", "both")}

\item{groupSample}{String. Used in the \code{groupPQN.} NULL if not "groupPQN". Default to "EQC" if "groupPQN" Other choice is "SQC".}

\item{dataTransform}{String. A transformation method to transform the data after \code{dataNormalize}.
\itemize{
\item "none": No data transformation is done.
\item "log10: Perform log10 transformation.
\item "sqrt": Perform square root transformation.
\item "cbrt": Perform cube root transformation.
}}

\item{dataScalePCA}{String. A data scaling done to the data after \code{dataTransform}. This data will be used later for Principal Component Analysis (PCA) "only".
\itemize{
\item "none": No data scaling is performed.
\item "mean: Mean-centered only
\item "meanSD": Mean-centered and divided by SD of each feature
\item "meanSD2": Mean-centered and divided by the square root of SD of each feature. Also called pareto-scaling.
}
Defaults to "meanSD".}

\item{dataScaleOPLSDA}{String. A data scaling done to the data after \code{dataTransform}. This data will be used later for analyses "other than PCA", e.g., Orthogonal Partial Least Squares-Discriminant Analysis (OPLS-DA), among others.
\itemize{
\item "none": No data scaling is performed.
\item "mean: Mean-centered only
\item "meanSD": Mean-centered and divided by SD of each feature
\item "meanSD2": Mean-centered and divided by the square root of SD of each feature. Also called pareto-scaling.
}
Defaults to "meanSD2".}

\item{outliers}{A vector of biological samples and/or QC that are considered as outliers. Example format is "c('Sample1', 'Sample2', 'QC1', 'QC2', ...)".}
}
\value{
A list of results from all of the tests done (e.g., batch-corrected data, normalized data, transformed data, scaled data, etc.)
}
\description{
This function performs data preprocessing techniques in bioinformatics to prepare the data for downstream analysis.
The data preprocessing includes data filtration, drift correction, data normalization, transformation, scaling,
and removal of known or identified outliers.
}
\examples{
\dontrun{
# Using the default parameters
mydata <- performPreprocessingPeakData(
 raw_data = org_data
)
}
}
