---
title: "Complete Metabolomics Analysis Workflow"
author: "John Lennon L. Calorio"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Complete Metabolomics Analysis Workflow}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 12,
  fig.height = 8,
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(MetaboStatR)
library(dplyr)
library(ggplot2)
library(knitr)
```

# Complete Metabolomics Analysis Workflow

This vignette demonstrates a complete metabolomics analysis workflow
using **MetaboStatR**, from raw data import to final results export.
We'll work through a realistic example that covers all major steps in
metabolomics data analysis.

## Study Design Example

For this tutorial, we'll analyze a hypothetical clinical study examining
metabolic differences between:

-   **Control group**: Healthy individuals (n=30)
-   **Less Severe Case**: Patients with mild condition (n=25)
-   **Severe Case**: Patients with severe condition (n=20)

The study includes:

-   3 analytical batches
-   Technical replicates for quality control
-   150 metabolites measured using LC-MS
-   Normalization weights (e.g., sample volume, protein concentration)

## Step 1: Data Quality Check and Import

The first step is to examine your raw data and ensure it meets
MetaboStatR's format requirements.

### Understanding the Data Structure

MetaboStatR expects data in a specific format with 8 metadata rows
followed by metabolite data:

```{r eval=FALSE}
# Your CSV file should look like this:
# Row 1: Sample names (must be unique)
# Row 2: Subject ID (for paired/longitudinal studies)  
# Row 3: Technical replicate IDs
# Row 4: Group assignments
# Row 5: Batch numbers
# Row 6: Injection sequence
# Row 7: Normalization values
# Row 8: Response variable (for regression)
# Row 9+: Metabolite data
```

### Load and Inspect Raw Data

```{r eval=FALSE}
# Load and perform initial quality check
data_qc <- perform_DataQualityCheck("path/to/your/metabolomics_data.csv")

# This function will:
# - Check data format and structure
# - Identify potential issues
# - Generate summary statistics

# View the structure of imported data
str(data_qc)
```

### Expected Output Structure

The `perform_DataQualityCheck()` function returns a list containing:

```{r eval=FALSE}
# Example of what data_qc contains:
names(data_qc)
# [1] "raw_data"            # Original data matrix
# [2] "metadata_summary"    # Sample information (first 8 rows)
# [3] "processing_log"      # Metabolite abundance matrix
# [4] "quality_checked_data # The quality checked data
```

## Step 2: Comprehensive Data Preprocessing

The preprocessing pipeline in MetaboStatR follows a carefully designed
sequence to ensure optimal data quality.

### Understanding the Preprocessing Steps

The 10-step preprocessing pipeline:

1.  **Outlier removal** - Remove obvious outlier samples
2.  **Feature filtering** - Remove metabolites with excessive missing
    values
3.  **Missing value imputation** - Fill remaining missing values
4.  **Drift/batch correction** - Correct for analytical drift and batch
    effects
5.  **Uncorrected feature removal** - Remove features that couldn't be
    corrected
6.  **Data normalization** - Account for technical variations
7.  **Data transformation** - Stabilize variance (log10, vsn)
8.  **Data scaling** - Standardize feature ranges
9.  **RSD filtering** - Remove features with high technical variability
10. **Low variance filtering** - Remove uninformative features

### Run Preprocessing with Default Parameters

```{r eval=FALSE}
# Use default preprocessing parameters (recommended for most studies)
processed_data <- perform_PreprocessingPeakData(
  raw_data = data_qc
)

# View preprocessing summary
print(processed_data$preprocessing_summary)
```

### Customizing Preprocessing Parameters

For advanced users, parameters can be customized:

```{r eval=FALSE}
# Example with custom parameters
processed_data <- perform_PreprocessingPeakData(
  raw_data = data_qc,
  
  # Step 1: Outlier removal
  outliers = c("Sample1, Sample2, Sample3"),
  
  # Step 2: Feature filtering  
  filterMissing = 0.2,  # Remove features missing in >20% samples in all group (since "filterMissing_by_group" = TRUE)
  filterMissing_by_group = TRUE,
  
  # Step 3: Missing value imputation
  denMissing = 5,  # 1/5 of minimum value
  
  # Step 4: Drift/batch correction
  driftBatchCorrection = TRUE,
  
  # Step 6: Normalization
  dataNormalize = "Normalization",  # Use values from row 7
  
  # Step 7: Transformation
  dataTransform = "log10",  # or "vsn", "sqrt", "log2", "sqrt", "cbrt"
  
  # Step 8: Scaling
  dataScalePCA = "meanSD", # mean centering + unit variance (for PCA and other analyses)
  dataScalePLS = "mean2SD",  # pareto scaling (exclusive for PLS-related analyses)
  
  # Step 9: RSD filtering
  filterMaxRSD = 30,  # Remove features with RSD > 30%
  filterMaxRSD_by = "EQC", # Perform it specifically on "EQC" QC samples
  
  # Step 10: Variance filtering
  filterMaxVarSD = 10  # Remove low-variance features
)
```

This should output a plot of six (6) random features of the before- and
after the data preprocessing steps. This plot is specific to drift- and
batch correction.

### Preprocessing Quality Assessment

```{r eval=FALSE}
# Compare before and after preprocessing
plot_BeforeAfter(
  data = processed_data,
  scaled = "PCA",
  group_by = "Sample", # Plot the samples or features/metabolites using "Features"
  n_random_samples = 30L, # Plot 30 random sample
  n_random_features = 30L, # Plot 30 random features/metabolites
  seed = NULL # Keep it random
)
```

## Step 3: Principal Component Analysis (PCA)

PCA provides an overview of data structure, sample clustering, and
potential batch effects.

### Perform PCA Analysis

```{r eval=FALSE}
# Perform PCA with multiple component comparisons
pca_results <- perform_PCA(
  processed_data,
  # Compare different PC combinations
  pc_combinations = list(
    c(1, 2),  # PC1 vs PC2
    c(1, 3),  # PC1 vs PC3  
    c(2, 3)   # PC2 vs PC3
  )
)

# Display all PCA plots together
display_AllPlots(pca_results)
```

## Step 4: OPLS-DA Analysis

Orthogonal Partial Least Squares Discriminant Analysis identifies
metabolites that discriminate between groups.

### Perform OPLS-DA

```{r eval=FALSE}
# Perform OPLS-DA with group arrangement (severe → control)
plsda_results <- perform_PLS(
  data = processed_data,
  method = "oplsda",
  arrangeLevels = c("Severe Case", "Less Severe Case", "Control")
)

# View OPLS-DA summary
print(plsda_results$model_summary)
```

### Model Validation and Performance

You can check the OPSL-DA model performances via the output in the
console or the output in the "Plots" or "Viewer" pane. Performance
metrics include

-   R2X
-   R2Y
-   Q2

are all the things you need to consider.

### VIP Scores and Feature Importance

VIP plots are automatically outputted in the "Plots" pane.
Features/Metabolites with VIP score \> 1 are generally considered
important.

## Step 5: Fold Change Analysis

Calculate effect sizes and magnitude of metabolite changes between
groups.

### Calculate Fold Changes

```{r eval=FALSE}
# Calculate fold changes (severe → control arrangement)
fc_results <- perform_FoldChange(
  data = processed_data,
  arrangeLevels = c("Severe Case", "Less Severe Case", "Control")
)
```

One of the results of this analysis are the fold changes and the log2 of
them. It will just be a matter of grabbing them them using the dollar
sign (\$).

## Step 6: Statistical Analysis

Perform comparative analysis with appropriate statistical tests and
multiple testing correction. This step will automatically detect how
many groups you have. For 2 groups, it will perform t-tests and/or
Wilcoxon Sum Rank test; for 3 or more groups, it will perform Analysis
of Variance (ANOVA) or Kruskal-Wallis test. The choice depends on the
assumption tests.

### Comprehensive Statistical Testing

```{r eval=FALSE}
# Perform statistical analysis with Benjamini-Hochberg correction
stats_results <- perform_ComparativeAnalysis(
  data = processed_data,
  adjust_p_method = "BH"  # False Discovery Rate control
)

# View statistical summary
print("Statistical Analysis Summary:")
print(stats_results$summary_statistics)
```

## Step 7: AUROC Analysis

Assess the discriminatory power of individual metabolites using Area
Under ROC Curve.

### Perform AUROC Analysis

```{r eval=FALSE}
# Calculate AUROC for all metabolites (control → severe arrangement)
auroc_results <- perform_AUROC(
  data_PP = processed_data,     # Preprocessed data
  data_DR = plsda_results,      # OPLS-DA results
  data_FC = fc_results,         # Fold change results
  data_CA = stats_results,      # Statistical results
  arrangeLevels = c("Control", "Less Severe Case", "Severe Case")
)
```

This function also outputs the top 5 (or as set by you)
features/metabolites with the highest AUC values.

## Step 8: Regression Analysis

Build predictive models using regularized regression methods. This
package primarily provides 2 regularized regression methods, elastic net
regression and Least Absolute Shrinkage and Selection Operator (LASSO).

### Elastic Net Regression

```{r eval=FALSE}
# Perform Elastic Net regression
regression_results <- perform_Regression(
  data = processed_data,
  method = "enet"  # Elastic Net (combines Ridge and LASSO)
)
```

### LASSO Regression

```{r eval=FALSE}
# Perform LASSO regression for feature selection
lasso_results <- perform_Regression(
  data = processed_data,
  method = "lasso"
)
```

## Step 9: Comprehensive Visualization

Create publication-ready plots to visualize your results.

### Volcano Plot

```{r eval=FALSE}
# Create volcano plot combining fold changes and statistical significance
plot_Volcano(
  PPData = processed_data,
  FCData = fc_results,
  CAData = stats_results,
  arrangeLevels = c("Severe Case", "Less Severe Case", "Control"),
  fcUP = 2,           # Upper fold change threshold
  fcDown = 0.5,       # Lower fold change threshold  
  adjpvalue = 0.05    # Adjusted p-value threshold
)
```

## Step 10: Export Results

Export all data frames and visualizations for further analysis or
publication.

### Export Data Tables to Excel

```{r eval=FALSE}
# Export all analysis results to Excel workbooks
perform_Export2Excel(
  results = list(
    processed_data,
    pca_results,
    plsda_results,
    fc_results,
    stats_results,
    auroc_results,
    regression_results
  ),
  folder_name = "MetaboStatR_Results",
  file_name = c(
    "01_ProcessedData",
    "02_PCA_Analysis", 
    "03_OPLSDA_Analysis",
    "04_FoldChange_Analysis",
    "05_Statistical_Analysis",
    "06_AUROC_Analysis",
    "07_Regression_Analysis"
  )
)
```

### Export Plots to High-Resolution Images

```{r eval=FALSE}
# Export all plots to PNG files
perform_ExportPlots2Image(
  results = list(
    processed_data,
    pca_results,
    plsda_results,
    fc_results,
    stats_results,
    auroc_results,
    regression_results
  ),
  folder_name = "MetaboStatR_Plots",
  file_prefix = c(
    "ProcessedData",
    "PCA",
    "OPLSDA", 
    "FoldChange",
    "Statistics",
    "AUROC",
    "Regression"
  ),
  image_format = "png",
  width = 15,
  height = 12,
  dpi = 300
)
```

## Results Interpretation Guide

### Key Findings to Report

1.  **Data Quality**:
    -   Original vs. final dataset dimensions
    -   Preprocessing steps applied and their impact
    -   Batch effect correction effectiveness
2.  **Exploratory Analysis**:
    -   PCA variance explained by each component
    -   Group separation in PCA space
    -   Identification of outlier samples
3.  **Discriminant Analysis**:
    -   OPLS-DA model performance (R2X, R2Y, Q2)
    -   Cross-validation results
    -   Top discriminating metabolites (VIP \> 1.0)
4.  **Biomarker Discovery**:
    -   Number of significantly different metabolites
    -   Effect sizes (fold changes)
    -   Biomarker performance (AUROC values)
5.  **Predictive Modeling**:
    -   Regression model performance
    -   Selected metabolite panels
    -   Model generalizability

## Troubleshooting Common Issues

### Low Model Performance

If OPLS-DA Q2 \< 0.4 or regression accuracy \< 0.7:

-   Check for batch effects in PCA plots
-   Consider additional preprocessing steps
-   Verify group assignments are correct - Check for outlier samples

### Few Significant Features

If \< 10% of features are significant:

-   Review statistical power and sample sizes
-   Consider less stringent significance thresholds
-   Check data transformation effectiveness
-   Validate with orthogonal analytical methods

### Poor Group Separation

If groups don't separate well in PCA:

-   Ensure biological differences exist between groups
-   Check for confounding variables (age, sex, BMI)
-   Consider stratified analysis
-   Validate sample collection and storage protocols

## Advanced Analysis Options

### Pathway Analysis

This function is not yet available. To be added.

```{r eval=FALSE}
# Perform pathway enrichment analysis
pathway_results <- perform_PathwayAnalysis(
  significant_features = significant_features,
  fold_changes = fc_results$log2_fold_changes,
  database = "KEGG"  # or "BioCyc", "Reactome"
)
```

### Time-Series Analysis

This function is not yet available. To be added.

```{r eval=FALSE}
# For longitudinal studies with multiple time points
timeseries_results <- perform_TimeSeriesAnalysis(
  data = processed_data,
  time_column = "TimePoint",
  subject_column = "SubjectID"
)
```

### Network Analysis

This function is not yet available. To be added.

```{r eval=FALSE}
# Build metabolite correlation networks
network_results <- perform_NetworkAnalysis(
  data = processed_data,
  significant_features = significant_features,
  correlation_method = "spearman"
)
```

## Session Information

```{r}
sessionInfo()
```

------------------------------------------------------------------------

This completes the comprehensive MetaboStatR workflow. The analysis
pipeline provides a robust foundation for metabolomics biomarker
discovery and should be adapted based on your specific research
questions and study design.

For additional support or advanced applications, please refer to the
other vignettes or contact the package maintainer.
